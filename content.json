{"pages":[],"posts":[{"title":"64-system-01","text":"","link":"/2019/08/06/64-system-01/"},{"title":"深入了解C++（4）——lambda表达式","text":"&emsp;本文主要记录常见的lambda表达式的用法。 一 lambda表达式简介&emsp;lambda表达式是一个函数，但是它是一个匿名函数，也就是没有名称的函数。通常而言这种函数在代码中仅被调用一次，因此直接在函数内部定义它，以此来提高程序的逻辑性和可读性。 &emsp;通常而言一个lambda函数展现为下面的形式 1[capture](parameters) mutable -&gt;return-type{statement} [capture]：捕捉列表。捕捉列表总是出现在Lambda函数的开始处。实际上，[]是Lambda引出符。编译器根据该引出符判断接下来的代码是否是Lambda函数。捕捉列表能够捕捉上下文中的变量以供Lambda函数使用; (parameters)：参数列表。与普通函数的参数列表一致。如果不需要参数传递，则可以连同括号“()”一起省略; mutable：mutable修饰符,用来说用是否可以修改捕获的变量。默认情况下，Lambda函数总是一个const函数，mutable可以取消其常量性。在使用该修饰符时，参数列表不可省略（即使参数为空）; 在值捕获时，加了mutable修饰符，才可以修改捕获变量。尽管可能在表达式的函数体中修改了捕获变量，但由于是值捕获（复制，拷贝），改变了的捕获变量，不影响捕获的变量；没加mutable修饰符时，不能修改；在引用捕获时，不管加不加mutable修饰符，都可以修改捕获变量，由于是引用捕获，原来的捕获变量也改变了。 -&gt;return-type：返回类型。用追踪返回类型形式声明函数的返回类型。我们可以在不需要返回值的时候也可以连同符号”-&gt;”一起省略。 如果function body中存在return语句，则该Lambda表达式的返回类型由return语句的返回类型确定； 如果function body中没有return语句，则返回值为void类型。 {statement}：函数体。内容与普通函数一样，不过除了可以使用参数之外，还可以使用所有捕获的变量。 二 简单的lambda表达式12345678910int main(){[] {}();//[]代表lambda表达式的开始，{}代表函数体，什么都没有，()代表调用函数.}//等价于=&gt;void f(){ }int main(){ f();} 123456789 //包含返回值的lambda表达式与其调用方式。 int main(){ [] { cout &lt;&lt; \"Hello, World!\"; }(); auto lam =[]() -&gt; int { cout &lt;&lt; \"Hello, World!\"; return 1; }; auto ret = lam(); auto lam2 =[]() -&gt; string { cout &lt;&lt; \"Hello, World!\"; return \"test\"; }; auto ret1 = lam2();} 三 lambda表达式捕获变量功能 [] 不捕获任何变量 [&amp;] 以引用方式捕获所有变量 [=] 用值的方式捕获所有变量（可能被编译器优化为const &amp;) [=, &amp;foo] 以引用捕获foo, 但其余变量都靠值捕获 [&amp;, foo] 以值捕获foo, 但其余变量都靠引用捕获 [bar] 以值方式捕获bar; 不捕获其它变量 [this] 捕获所在类的this指针 123int a=1,b=2,c=3;auto lam2 =[&amp;,a](){ cout &lt;&lt; a&lt;&lt;b&lt;&lt;c&lt;&lt;endl;};//b，c以引用捕获，a以值捕获。lam2(); 12vector&lt;string&gt; address{\"111\",\"222\",\",333\",\".org\",\"wwwtest.org\"};for_each(address.begin(),address.end(),[](string&amp; str){cout&lt;&lt;str&lt;&lt;endl;}); 四 使用function传递lambda表达式1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;functional&gt;#include &lt;string&gt; void print(std::function&lt;std::string ()&gt; const &amp;f){ std::cout&lt;&lt;f()&lt;&lt;std::endl;} int main() { std::cout &lt;&lt; \"Hello, World!\" &lt;&lt; std::endl; int num = 101; auto a = [&amp;]//以引用的方式捕获本函数中的变量 () //无参数 -&gt;std::string {//返回值的类型为std::string return std::to_string(num); }; print(a); num++; print(a); return 0;}","link":"/2019/07/24/cpp-lambda/"},{"title":"深入了解C++（5）—— C++11 std::thread多线程编程","text":"&emsp;按理来说学习多线程编程应该从深入浅的来学，但是由于学习的内容实在是有一些偏差，所以最后还是决定从stl标准库开始，学习C++多线程编程。 一 std::thread函数浅析&emsp;相比pthread，C++11提供了一个调用非常简单的多线程库std::thread。std::thread的构造函数方便得出人意料，这得感谢std::bind这个神奇的函数。在std::thread的构造函数里，你可以直接传递一个函数和这个函数的参数列表给这个线程。你甚至可以传递一个类成员函数。如果你这么做了，参数列表的第二个参数（第一个参数是被传递的成员函数）会被作为该类成员函数所作用的实例。 12345678910// 假设buy是一个可调用的函数对象，它即可能是函数指针，也可能是函数对象std::thread Annie(buy);// Annie会去执行buy()std::thread Bob(buy, book, food);// Bob会去执行buy(book, food) // 假设buy是Consumer的一个可调用的成员函数Consumer Clara;std::thread action(buy, Clara, phone);// Clara会去执行Consumer.buy(phone) 12pthread_create(&amp;thread, &amp;attr, f, static_cast&lt;void *&gt;(&amp;args));// 其中f是函数，args是所有参数打包成的结构体。因为pthread_create的第四个参数类型是void*，所以需要强制转型 &emsp;简单的mutex互斥锁实例 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include&lt;thread&gt;#include&lt;mutex&gt;std::mutex mut;class A{public: volatile int temp; A(){ temp=0; } void fun(int num){ int count=10; while(count&gt;0){ mut.lock(); temp++; std::cout&lt;&lt;\"thread_\"&lt;&lt;num&lt;&lt;\"...temp=\"&lt;&lt;temp&lt;&lt;std::endl; mut.unlock(); count--; } } void thread_run(){ std::thread t1(&amp;A::fun,this,1); std::thread t2(&amp;A::fun,this,2); t1.join(); t2.join(); }};int main(){ A a; a.thread_run();} 二 volatile 关键词&emsp;在C++中使用volatile关键词可以防止编译器做出错误的优化。当一个线程对一个关键字进行多次读取时，编译器可能会把变量放入寄存器中，而不会每次都从内存中读取，这样如果变量在其他地方修改，会发生脏读取错误。 三 基于std::thread实现的生产者消费者模型。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;chrono&gt;#include &lt;condition_variable&gt;#include &lt;future&gt;#include &lt;mutex&gt;#include &lt;queue&gt;// 注意某些调用可能会抛出std::system_error，需要对其进行处理。std::mutex mutex;std::condition_variable condvar;std::queue&lt;int&gt; msgQueue;void producer(int start, int end){ for (int x = start; x &lt; end; x++) { std::this_thread::sleep_for(std::chrono::milliseconds(200)); { std::lock_guard&lt;std::mutex&gt; guard(mutex); msgQueue.push(x); } printf(\"Produce message %d\\n\", x); condvar.notify_all(); }}void consumer(int demand){ while (true) { std::unique_lock&lt;std::mutex&gt; ulock(mutex); condvar.wait(ulock, []{ return msgQueue.size() &gt; 0;}); // wait的第二个参数使得显式的double check不再必要 printf(\"Consume message %d\\n\", msgQueue.front()); msgQueue.pop(); --demand; if (!demand) break; }}int main(){ std::thread producer1(producer, 0, 10); std::thread producer2(producer, 10, 20); std::thread producer3(producer, 20, 30); std::thread consumer1(consumer, 20); std::thread consumer2(consumer, 10); producer1.join(); producer2.join(); producer3.join(); consumer1.join(); consumer2.join();} &emsp;本文仅简单介绍std::thread的基本操作，更加复杂的操作以及更多的功能将在日后进一步研读。","link":"/2019/07/26/cpp-thread/"},{"title":"深入了解C++（6）—— 单例模式设计","text":"&emsp;在C++中，单例模式是一种非常常见的设计模式。单例模式主要需要实现下面的两个功能。 不能在外部通过构造函数构造，否则一个类将会被多次初始化。 每一个对象只能产生一个实例。 1脑壳疼 缓更。","link":"/2019/07/27/cpp-singleton-mode/"},{"title":"算法基础——dijkstra算法","text":"&emsp;发现时间久了脑子稍微有点糊，今天不想总结新的面试知识了，为了保持工作热度，回顾一下以前学习的知识。所以在在这里稍微总结一下迪杰斯特拉算法。也称最短路算法。 一 基础版n^2实现123456789101112memset(v, 0, sizeof(v)); for(int i = 0; i &lt; n; i++) d[i] = (i==0 ? 0 : INF); for(int i = 0; i &lt; n; i++) { int x, m = INF; for(int y = 0; y &lt; n; y++) if(!v[y] &amp;&amp; d[y] &lt;= m) m = d[y], x = y; v[x] = 1; for(int y = 0; y &lt; n; y++) d[y] = min(d[y], d[x] + w[x][y]); } 二 利用边集和优先级队列Mlog(N)实现&emsp;首先需要定义边，边的定义如下。 123456struct DistNode { int d, u; bool operator &lt; (const HeapNode&amp; rhs) const { return d &gt; rhs.d; //这样一来，队列中在最顶层的是最小值 }} &emsp;使用优先级队列进行优化。 12345678910111213141516priority_queue&lt;Node&gt; q;memset(vis,0,sizeof(vis));for(int i = 1;i &lt;= n;i++) d[i] = INF;d[1] = 0;q.push(make_pair(d[1],1));while(!q.empty()) { Node t = q.top();q.pop(); if(vis[t.second])continue; vis[t.second] = 1; for(int i = 1;i &lt;= n;i++) if(!vis[i] &amp;&amp; d[i] &gt; t.first+G[t.second][i]) { d[i] = t.first+G[t.second][i]; q.push(make_pair(d[i],i)); }} &emsp;算法比较简单暂时先不做过多的讲解，然后更新这个主要还有一个原因就是回家了但是不想划水太严重。所以暂时先更新这个不带过多讲解的版本啦。等23号正式开始给暑期集训讲课的时候在对内容进行更深一步的优化。","link":"/2019/07/19/algorithm-graph/"},{"title":"数据结构基础总结","text":"&emsp;经过漫长的等待后，果然头条的面试挂掉了。突然发现自己打了这么久的ACM，很多基础数据结构的概念掌握的还不是非常的牢固。这些数据结构可能并不难，特别是跳表和线段数组这样的数据结构，但是由于平日的疏忽导致这些概念有少许的以往。那么今天就要对这些掌握不是特别牢固的数据结构一一进行总结。 一 跳表 &emsp;跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。&emsp;跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。&emsp;跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。 &emsp;假设每M个元素构建索引，元素链表中总共有N个元素，那么构建的索引数如下： 第一级有：n/M 个第二级有：n/(M^2)个元素…….第k级有：n/(M^k)个元素 &emsp;假设第k级为最后一级则可知，n/(M^k) = M, k = logn - 1, 再加上原始链表总共logn级平均每级搜索元素个数 = M + 1 ; 时间复杂度 = O(log(n)) 空间复杂度 = n/M + n/(M^2) + … + n/(M^k) = O(n) 引用自简书liuzhengqiu 二 线段树&emsp;了解线段树前我们需要了解二叉树，线段树是二叉树的一种，他是一颗二叉搜索树。线段树上的每一个节点代表一个区间，同样也可以理解为一个线段，搜索则是在这些线段上进行搜索从而获得答案。 &emsp;为了进一步的学习线段树，我们首先需要了解线段树的功能是什么，有过OI基础/ACM基础的同学们通常会认为线段树主要用于处理区间查询问题。但是在实际应用中可能线段树的功能比区间查询更加丰富，当然这里我们还是需要从区间查询问题开始说起。 更新点，查询区间更新区间，查询点更新区间，查询区间 &emsp;通常来说，利用线段树处理的问题分为上面三种，通常而言线段树的时间复杂度是O(log2(N))，线段树的空间复杂度&lt;4n。下面通过一张图来显示线段树每个节点储存的信息，例子采用的是区间长度为10的数组。 &emsp;可以发现，每个叶子结点的值就是数组的值，每个非叶子结点的度都为二，且左右两个孩子分别存储父亲一半的区间。每个父亲的存储的值也就是两个孩子存储的值的最大值。 &emsp;通过对上图的观察我们现在可以清晰的了解线段树点更新，区间更新，点查询，区间查询的方法。具体的代码需要在网上寻找，每个人都有自己独特的写法，如果是竞赛选手，强烈建议形成自己的一套模板。 参考CSDN代码 三 线段数组&emsp;要了解线段数组，我们需要先了解树状数组，顾名思义，树状数组即利用数组构建树形结构。这种结构相比树形结构可以极大程度的降低内存的消耗，故在比赛中我们常常利用树状数组来解决线段树的问题，而不是动态开点。 &emsp;与普通的线段树相同，利用线段数组可以轻松的完成区间的修改、查询。他的复杂度和线段树相同均为O(logN)，但是相比线段树，树状数组拥有更小的常数，所以最终运行的速度更快。 四 红黑树红黑树具有下面五种特征： 性质1：每个节点要么是黑色，要么是红色。性质2：根节点是黑色。性质3：每个叶子节点（NIL）是黑色。性质4：每个红色结点的两个子结点一定都是黑色。性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 &emsp;红黑树是一种特殊的二叉平衡树，它通过左旋，右旋和变色来保持自平衡。他是一个非常负责的数据结构，在本篇中仅简单介绍其功能。更加丰富的内容日后会开专题介绍。","link":"/2019/07/12/data-structure/"},{"title":"LRU算法读取淘汰双O（1）算法","text":"&emsp;再次简介一下这个算法LRU全称是Least Recently Used,即最近最久未使用的意思。算法每一次将最久未使用的块更新出去。但是呢上一篇笔记附上的百度的代码复杂度实在不堪入目，所以该写还是得写，刚好也分享给大家这个百度前几页没有的O(1)算法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;const int cache_size = 10;const int memory_size = 100;struct cache_node{ cache_node* l_link; // 栈的链接 cache_node* r_link; int cache_id; // cache_id int cache_val; // chache 映射位置};void init(cache_node*&amp;head,cache_node*&amp;tail){ head=new cache_node({nullptr,nullptr,0,-1}); cache_node *tmp=head; for(int i(1); i&lt;cache_size; i++) { cache_node *x = new cache_node({tmp,nullptr,0,-1}); tmp-&gt;r_link=x; tmp = x; } tail = tmp;}int main(){ vector&lt;cache_node*&gt;memory_to_cache(memory_size,nullptr); cache_node *head,*tail; init(head,tail); int n; cin&gt;&gt;n; //n代表输入的数组组数，然后x代表这一次访问的对象，平均每次访问更新需要6次赋值，所以这个不是一个原子操作。假如cpu内部实现真的存在这种模式,内部大概会有许多门电路来使这多次赋值成为一个原子操作。 for(int i(0); i&lt;n; i++) { int x; cin&gt;&gt;x; if(memory_to_cache[x]==nullptr) { cout&lt;&lt;tail-&gt;cache_val&lt;&lt;\"被清出\"&lt;&lt;endl; cout&lt;&lt;x&lt;&lt;\"移入栈顶\"&lt;&lt;endl; if(tail-&gt;cache_val!=-1) memory_to_cache[tail-&gt;cache_val]=nullptr; tail-&gt;l_link-&gt;r_link=nullptr; tail-&gt;r_link=head; head-&gt;l_link=tail; tail=tail-&gt;l_link; head=head-&gt;l_link; head-&gt;l_link=nullptr; head-&gt;cache_val=x; memory_to_cache[x]=head; } else { if(head==memory_to_cache[x]) continue; else { cout&lt;&lt;x&lt;&lt;\"移入栈顶\"&lt;&lt;endl; memory_to_cache[x]-&gt;l_link-&gt;r_link=memory_to_cache[x]-&gt;r_link; if(memory_to_cache[x]-&gt;r_link!=nullptr) memory_to_cache[x]-&gt;r_link-&gt;l_link=memory_to_cache[x]-&gt;l_link; else { tail=memory_to_cache[x]-&gt;l_link; } memory_to_cache[x]-&gt;l_link=nullptr; memory_to_cache[x]-&gt;r_link=head; head-&gt;l_link=memory_to_cache[x]; head=memory_to_cache[x]; } } } return 0;} &emsp;完整的代码就是上面附的这一些了，然后由于代码比较简单主要是考察逻辑，所以也不再附更多的注释了。值得注意的是上面的代码的第一层if else中有数行功能相同，其实可以通过调整代码位置使其合并。但是过度合并可能会造成一些可读性缺失，这里就不再做深层次的代码优化了。","link":"/2019/07/18/LRU-O1/"},{"title":"初窥http（1）——浏览器中输入url后到底发生了什么","text":"&emsp;在学校里学习计算机网络的过程中，由于《计算机网络》课本内容较为底层基础，许多人在学习完这本书后都会产生一定的困惑。譬如，现在互联网有哪些地方运用到了哪些协议，这些协议最新的标准是什么样子的等等。为了解决心中的困惑，我决定先对日常中最常用的http-web中所采用的协议进行更深一步的了解，为此我在图灵社区中购置了《图解http》一书。接下来将按照自己的思路从书中获取一些问题的答案。 &emsp;本文是购置该书籍后发表的第一篇记录，在这篇记录里，我将揭秘在浏览器中输入url后发生的一系列事情。 浏览器中输入url后主要会发生下面的几件事 一 负责域名解析的DNS服务&emsp;计算机可以被赋予ip地址，同样的也可以被赋予主机名和域名。例如本博客的ip地址是185.199.109.153（github io服务器地址），域名地址为 blog.100innovate.com。我们通常使用域名去访问不同的计算机和网站，域名相比一串数字来说更有利于人们的记忆，但是计算机更擅长于处理ip地址这样的数字。 &emsp;为了解决计算机和人的矛盾，DNS服务在这个时候就产生了，通过DNS服务我们可以通过域名查询ip，或者利用ip查询域名。（通常而言，人们仅利用域名查询ip，很少利用ip查询域名） &emsp;在浏览器中输入url并键入回车后的第一步，浏览器将会向DNS服务器发送查询请求，从而获取目标服务器的ip地址。 二 互联网的基础TCP/IP协议&emsp;计算机想要相互通信，就需要一个标准的数据交换协议，这个协议就是TCP/IP协议。通常而言浏览器访问web网站时采用的是TCP协议，TCP协议是一种面向连接的、可靠的、基于字节流的传输层通信协议，为了保证通信的可靠新，首先需要进行三次握手，三次握手的主要流程为：1.客户端向服务器端发送SYN标记的数据包2.服务器端向客户端发送SYN/ACK标记的数据包3.客户端向服务器端发送ACK标记的数据包 &emsp;采用三次握手而不是两次握手有许多原因，原因之一是防止延期到达的数据包传输到服务器，服务器会因此创建一个无效的连接。 三 通过HTTP协议传输数据&emsp;HTTP协议的职责是生成针对目标Web服务器的HTTP请求报文，主要有如下的请求方法： GET:获取资源POST:传输实体主体HEAD:获取报文首部PUT:传输文件DELETE:删除文件OPTIONS:询问支持的方法TRACE:追踪路径…… &emsp;利用上述的数种请求报文向服务器发送请求报文，从而获取用户需要访问的内容。请求报文主要包含请求方法、URI、协议版本三个信息。 &emsp;在向服务器发送完请求报文后，服务器会返回请求的结果。当然每一次返回的结果并非绝对正确，为了表达服务器对用户请求的各种状态，http协议设置了规定了状态码，通过返回状态码告知浏览器服务器处理的情况，状态码通常的定义如下： 状态码 类别 含义 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 &emsp;通常来说，只要遵守上述状态码的规则，服务提供商可以自行创建状态码。 &emsp;通过上述请求协议和服务器返回报文，最终浏览器可以获得用户需要的数据和信息。 四 浏览器解析并渲染页面&emsp;在浏览器成功获取html信息后，将会按照顺序从头至尾解析html文件，在解析到外部的css、js等其他外部资源文件的时候，根据服务器、浏览器的版本不同将会直接向服务器请求资源文件，或者重新建立TCP连接，然后请求资源文件。值得一提的是，在解析html文件时，浏览器将会构建DOM树，为了加速这一过程，浏览器还会使用预解析等功能。 &emsp;在完成html的解析后，浏览器还需要根据浏览器的窗口位置等信息，逐像素的将网页绘制出来。最终我们可以获得想要看到的网页。 五 小结&emsp;通过对《图解http》进行全篇大致浏览，解决了一大问题。但是需要学习的仍然还有人多，譬如现代浏览器一些处理机制问题以及近年来我们常常使用的https与http有什么不同，这些疑惑就留到日后逐一破解。","link":"/2019/07/10/http-01/"},{"title":"深入了解C++（2）——虚函数与虚函数底层实现","text":"&emsp;面向对象程序设计（object-oriented programming）是一个非常重要的概念，其核心思想是数据抽象、继承、动态绑定。在C++语言中，虚函数的作用是实现多态性。而纯虚函数则作为一个没有具体实现的虚函数，与java程序设计的influence非常相似。今天本篇文章将简要总结C++中的虚函数，并且深入研究C++虚函数的底层实现方式。 本文共分为四个部分 虚函数、纯虚函数、动态绑定、虚函数底层实现 一 虚函数&emsp;在C++中，虚函数的作用就是为了实现多态性，即父类为子类提供虚函数的默认实现。子类可以重写虚函数以实现自身的特殊化。一段最基本的包含虚函数的父类定义及子类定义如下： 1234567891011121314151617181920212223class A{public: virtual void output(string s) { cout&lt;&lt;\"A(output):\"&lt;&lt;s&lt;&lt;endl; }};class B:public A{ virtual void output(string s) { cout&lt;&lt;\"B(output):\"&lt;&lt;s&lt;&lt;endl; }};int main(){ A* ptr=new B(); ptr-&gt;output(\"hello\"); delete ptr;} &emsp;基于上述的代码，我们将得到“B(output):hello”的输出，注意一旦我们定义一个函数为虚函数，那么它将一直作为虚函数，子类无法改变该函数是虚函数这个事实。 二 纯虚函数&emsp;在C++中，如果一个类包含纯虚函数，那么这个类将成为一个抽象类。抽象类无法创建出对象，只有继承了抽象类的子类通过实现虚函数才能被实例化。纯虚函数的概念与java中的influence非常相近，它是一种只提供声明不提供实现的约束。子类需要一一将其全部实现。一个常见的纯虚函数实现如下： 12345678910111213class A{public: virtual void output(string s)=0;};class B:public A{ virtual void output(string s) { cout&lt;&lt;\"B(output):\"&lt;&lt;s&lt;&lt;endl; }}; &emsp;如果不想实现一个纯虚函数，那么继承它的类也将是一个抽象类。这个范例如下： 1234567891011121314151617class A{public: virtual void output(string s)=0;};class B:public A{ virtual void output(string s)=0;};class C:public B{ virtual void output(string s){ cout&lt;&lt;\"C(output):\"&lt;&lt;s&lt;&lt;endl; }}; 三 动态绑定&emsp;在了解虚函数的底层实现之前，首先需要了解的是动态绑定概念。 在执行期间（非编译期）判断所引用对象的实际类型，根据实际类型（动态类型）调用相应的方法。 动态绑定灵活性相对静态绑定来说要高，因为它在运行之前可以进行选择性的绑定，但同时，动态绑定的执行效率要低些，因为绑定对象还要进行编译（现在编译期一般都会多次编译）。触发动态绑定的条件： （1）只有指定为虚函数的成员函数才能进行动态绑定； （2）只有通过基类的指针或引用进行函数调用。 &emsp;了解了这个关键点后，我们发现我们需要去了解的重点是，如何进行动态绑定的概念，此时就涉及到了C++虚函数的底层实现。 四 虚函数的底层实现&emsp;简单查阅资料我们可以发现，C++虚函数的实现主要利用了虚函数表。编译器将为实现了虚函数的基类和覆盖了虚函数的派生类分别创建一个虚函数表(Virtual Function Table,VFT)。也就是说Base和Derived类都将有自己的虚函数表。实例化这些类的对象时，将创建一个隐藏的指针VFT*，它指向相应的VFT。可将VFT视为一个包含函数指针的静态数组，其中每个指针都指向相应的虚函数。Base类和Derived类的虚函数表如下图所示： 123456789101112131415161718192021222324252627282930class Base{public: virtual void Func1() { //Func1的实现代码 } virtual void Func2() { //Func2的实现代码 } //Func3、Func4等虚函数的实现 virtual void FuncN() { //FuncN的实现代码 }};class Derived:public Base{public: virtual void Func1() { //Func2覆盖Base类的Func1代码 } //除去Func2的其他所有虚函数的实现代码 virtual void FuncN() { //FuncN覆盖Base类的FuncN代码 }}; &emsp;如上图所示，利用上述代码编译后，编译器将会为base类和derived类提供虚函数表。当一个对象被实例化时，将会创建一个隐藏的指针指向对应的虚函数表，从而实现运行时多态。","link":"/2019/07/20/cpp-virtualfunction/"},{"title":"数据库基础——索引","text":"&emsp;下午马上就迎来新一轮面试了，突然想到昨天面试官提问关于数据库的问题，自己对这方面可以说是一窍不通，那么针对现代数据库，最重要的一环是建立索引值。索引可以极大的提升搜索的效率。下面以mysql为例，总结五种不同的索引方式。 一 普通索引&emsp;普通索引是最常见最基础的索引，建立一个普通索引没有任何限制条件，是我们平时最常利用的索引方式。 二 唯一索引&emsp;唯一索引与普通索引类似，不同的是唯一索引的值必须唯一，但允许存在空值。 三 主键索引&emsp;与唯一索引类似，但是主键索引除了内容必须唯一以外，内容不允许存在空值，而且一张表中只能包含一个主键索引。 四 组合索引&emsp;组合索引使用多个列的值构成索引，专门用于组合搜索的情况，其要求组合情况唯一。组合索引的效率大于索引合并。 五 全文索引&emsp;主要用来查找文本中的关键字，而不是直接与索引中的值相比较。全文索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。对于较大的表，全文索引需要消耗大量的硬盘空间，这是一种需要慎重使用的索引方式。","link":"/2019/07/16/database-base/"},{"title":"初窥http（2）——加密版本的http协议https协议","text":"&emsp;紧随初窥http（1），这次探索的是现代网站常用的加密协议https。https的主要功能是确保web安全。它主要弥补了http下面的几个不足： 使用明文通信，内容可能会被窃听无法验证通信方的身份，可能存在伪装的情况无法验证报文的完整性，报文可能遭到修改。 &emsp;这些问题通常会出现在所有非加密的信息传输协议中。为了解决上述的三个问题https应运而生。 一 什么是https&emsp;利用SSL或者TLS的组合使用，加密HTTP的通信内容。通过SSL建立安全通信线路之后，就可以在这条线路上进行HTTP通信。与SSL组合使用的HTTP被称为HTTPS或者HTTP over SSL。 二 对称加密非对称加密&emsp;对称加密和非对称加密是我们常常使用的加密算法，对称加密时通信双方使用同一个密钥，此时如何保障该密钥的传输成为一个重大难题，通常来说在一些必要的情况下设备厂商会在设备内预置一些密钥对，这样在一定程度上保证通信安全。而非对称加密，一对密钥由公钥和私钥组成，私钥解密公钥加密数据，公钥解密私钥加密数据。私钥只能由一个设备保管，但是公钥可以公开给所有人，根据算法相关的知识我们可以知道，这种通信方式更为安全，但是传输速度收到加密解密速度的影响。 &emsp;所以在https中，同时使用到了对称加密和非对称加密，非对称加密主要用于服务器的验证，对称加密主要用于大量数据的传输，利用对称加密和非对称加密的特点，共同解决http数据传输时的安全问题。 三 https过程详解&emsp;关于HTTPS安全通信机制和HTTPS的通信步骤，不同人有不同的理解办法，这里引用《图解http》里面的内容来详细介绍这一过程。 摘选书中的内容主要分为下面12个步骤。 客户端通过发送Client Hello报文开始SSL通信。报文中包含客户端支持的SSL的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。 服务器可进行SSL通信时，会以Server Hello报文作为应答。和客户端一样，在报文中包含SSL版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 之后服务器发送Certificate 报文。报文中包含公开密钥证书。 最后服务器发送Server Hello Done报文通知客户端，最初阶段的SSL握手协商部分结束。 SSL第一次握手结束之后，客户端以Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret的随机密码串。该报文已用步骤3中的公开密钥进行加密。 接着客户端继续发送Change Cipher Spec报文。该报文会 提示服务器，在此报文之后的通信会采用Pre-master secret 密钥加密。 客户端发送Finished报文。该报文包含连接至今全部报文 的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送Change Cipher Spec报文。 服务器同样发送Finished报文。 服务器和客户端的Finished 报文交换完毕之后，SSL连接就算建立完成。当然，通信会受到SSL的保护。从此处开始进行应用层协议的通信，即发送HTTP请求。 应用层协议通信，即发送HTTP响应。 最后由客户端断开连接。断开连接时，发送close_notify报文。上图做了一些省略，这步之后再发送TCP FIN报文来关闭与TCP 的通信。","link":"/2019/07/13/http-02/"},{"title":"头条三面凉经分析","text":"&emsp;非常惨淡的倒在了北京头条的三面上，首先觉得这个提前批的城市选择策略可能有误，太多人投递导致难度激增。第二个就是对操作系统算法的理解有天坑。这里需要弥补一下算法知识和一些深层的概念知识。 一 进程与线程在操作系统内核中的体现&emsp;这个问题首先问的是进程和线程是什么样子的，由于前面已经对这个问题进行过总结，所以在此不再进行复述。 &emsp;然后说实话看到这个问题简直是惊呆了，课程里面确实没有详细学习过linux系统。基于操作系统调度的基本单位是进程，所以当时直接答出来线程应该在内核中没有体现。但是时候查阅资料发现这个问题回答的实在不规范。下面贴出标准答案的回复。 &emsp;首先需要肯定的是进程和线程在操作系统内核中确实概念相似。在linux系统中，进程和线程或者其他调度单元都是利用 task_struct 这个结构体表示。 1234567struct task_struct {... pid_t pid; //标识不同的进程和线程 pid_t tgid; //用于标识线程组id，在同一进程中所有线程都具有同一tgid... struct *group_leader; //线程组中主线程的指针。} &emsp;进程还是线程的创建都是由父进程/父线程调用系统调用接口实现的。创建的主要工作实际上就是创建task_strcut结构体，并将该对象添加至工作队列中去。而线程和进程在创建时，通过CLONE_THREAD flag的不同，而选择不同的方式共享父进程/父线程的资源，从而造成在用户空间所看到的进程和线程的不同。引用自Zpeg &emsp;然后更加深入的去看待这个问题，无论以任何方式创建进程或者线程，在linux系统中最终都是去调用do_fork()函数。这个函数的原型是： 12345long do_fork(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr) clone_flags是一个标志集合，用来指定控制复制过程的一些属性。最低字节指定了在子进程终止时被发给父进程的信号号码。其余的高位字节保存了各种常数。 stack_start是用户状态下栈的起始地址。 stack_size是用户状态下栈的大小。 arent_tidptr和child_tidptr是指向用户空间中地址的两个指针，分别指向父子进程的PID。NPTL（Native Posix Threads Library）库的线程实现需要这两个参数。 &emsp;线程跟进程的区别主要就在于do_fork函数首先执行的copy_process中，当上层以pthread_create接口call到kernel时，clone_flag是有CLONE_PTHREAD标识 但CLONE_PTHREAD标识只在最后一个步骤（设置各个ID、进程关系）时体现：（current为当前进程/线程的task_struct结构体 ，p为新创建的结构体对象） 1234567if (clone_flags &amp; CLONE_THREAD) { p-&gt;group_leader = current-&gt;group_leader; p-&gt;tgid = current-&gt;tgid;} else { p-&gt;group_leader = p; p-&gt;tgid = p-&gt;pid;} 12345const int clone_flags = (CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SYSVSEM | CLONE_SIGHAND | CLONE_THREAD | CLONE_SETTLS | CLONE_PARENT_SETTID | CLONE_CHILD_CLEARTID | 0); &emsp;通过判断clone_flags中标记，即可控制子线程会与父线程共享虚拟地址空间、文件、信号等。 &emsp;本段的内容主要参考了Zpeg的博客，对博客中的部分内容进行精简，透过这里可以简要了解整体的流程。面对面试官的问题可以简要做如下回答：对于系统内核来说，进程和线程没有显著区别，它们在系统中都是一个task_struct结构体，他们的的主要差距是在主进程或者主线程进行系统调用的时候调用了do_fork()函数，然后do_fork函数中执行copy_process。在copy_process中有一个clone_flags，在创建线程的时候clone_flag是据有CLONE_PTHREAD标识的。 二 数据结构 b+树与跳表&emsp;b+树的最大优势是可以利用叶子节点相互链接的特性来进行区间查询。这个特性无法被普通排序二叉树前序遍历使用链表链接替代。因为普通排序二叉树使用链表链接时更新下一跳的系统消耗可能过大。 &emsp;跳表在非尾部进行插入删除时更新索引开销较大。这里与排序二叉树链表链接时更新下一跳类似。 &emsp;关于这两个数据结构更多的内容不再进行展开描述。具体可以参考各大搜索引擎的介绍（推荐google） 三 深度学习lstm如何解决梯度爆炸&emsp;这个问题我很吃惊，毕竟确实是本科生，制作深度学习模型的时候通常都是进行调库调试等操作。所以这里暂时不对这个模块进行扩展。来日方长，如果日后从事算法研究再战。 四 socket编程epoll模型的具体实现&emsp;针对select模型和epoll模型，前段时间已经有过了解，select模型是通过轮询来获取活跃的连接的。但是仅知道epoll模型不会轮询所以效率高，但是并不了解epoll模型内部具体实现，这里对epoll模型内部实现机制进行一点介绍。 1int epoll_create(int size); &emsp;首先我们需要关注的是epoll的创建函数，参照晚风_清扬的博客对该函数进行下面的描述。 epoll_ create时，内核除了帮我们在epoll文件系统里建了新的文件结点，将该节点返回给用户。并在内核cache里建立一个红黑树用于存储以后epoll_ctl传来的需要监听文件fd外，这些fd会以红黑树节点的形式保存在内核cache里，以便支持快速的查找、插入、删除操作。 1int int epoll_ctl(int epfd, intop, int fd, struct epoll_event *event); 内核还会再建立一个list链表，用于存储事件就绪的fd。内核将就绪事件会拷贝到传入参数的events中的用户空间。就绪队列的事件数组events需要自己创建，并作为参数传入这样才可以在epoll_wait返回时接收需要处理的描述符集合。当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。 1int epoll_wait(int epfd,struct epoll_event *events,int maxevents, int timeout); 所以epoll模型的整体工作流程如下： 执行epoll_create时，创建了红黑树 执行epoll_ctl时，创建就绪list链表，如果增加fd添加到红黑树上，然后向内核注册有事件到来时的回调函数，当设备上的中断事件来临时这个回调函数会向list链表中插入就绪的fd。 执行epoll_wait时立刻返回准备就绪链表里的数据即可 &emsp;这里真的是吃了一个没有学过网络编程的亏，所有的内容几乎都是面试前突击的，但是通过这样重重面试对这些模型内部细节逐步有了一个清晰的认识。 五 linux copy-on-write特性&emsp;其实很想跟面试官说，我真的真的真的没有系统的学习过linux操作系统，但是确实我学没学过跟你需要什么样的人才没有啥关系，只能吃一个哑巴亏回去赶紧补着点。 &emsp;copy-on-write 简单来说就是写时拷贝技术，该技术的主要目的时减少fork时复制主进程内存内容的时间开销。linux系统调用fork函数时，当进程未对内存内容进行修改的时候，此时将直接共享主进程的内存，此时子进程仅拥有对内存进行只读的权限。当需要对内存内容进行修改的时候，操作系统会先将内存copy一份，然后再进行写操作。 在页根本不会被写入的情况下—举例来说，fork()后立即调用exec()—它们就无需复制了。fork()的实际开销就是复制父进程的页表以及给子进程创建惟一的进程描述符。 六 连续抛硬币问题 问题描述:连续抛硬币，问出现正反反 和反反正的概率谁的更大概率是多少。 &emsp;面试的时候脑子有点糊，但是最后还是做出来了。分析过程大致如下： &emsp;首先考虑下面四种情况： 1/4 NN1/4 NF1/4 FN1/4 FF &emsp;我们可以快速的发现，如果出现了正，后续只可能出现正反反胜利的情况。所以反反正胜利的概率仅存在于前两次抛出反的情况。然后对于情况反反，只要出现一次正，则反反正胜利，所以正反反胜利的概率则是 1-1/4 = 3/4。 反反正的概率是1/4。 七 LRU最近替换算法 O（1）&emsp;看到这个问题实在是脑壳疼。操作系统课程上对这个内容学习的欠缺导致现在尴尬的局面。这个问题的解决非常非常的简单，利用一个映射数组和链表即可完成o（1）的更新和O（1）的访问。当然也可以利用hash_map和链表。个人推测cpu如果采用这种更新策略，应该使用的是映射数组的方式，这种方式更为稳定。这里需要 内存大小/页大小 的映射空间，在内存过大的时候可能并不是特别实用，所以推测现代cpu应该抛弃了这种方法，但是LRU算法仍然作为最经典的缓存算法被大家使用。 &emsp;因为心情郁闷这里就不对这个算法重新进行实现，摘选一个接近正确的代码放在下面: 1234567891011121314151617181920212223242526272829#include&lt;bits/stdc++.h&gt;using namespace std;typedef long long LL;const int maxn=500005;int n,m,x,cnt,stk[110],pos[maxn];int main(){ while(cin&gt;&gt;n&gt;&gt;m){ cnt=0; memset(pos,0,sizeof(pos));//标记页面在栈中的位置 while(m--){ cin&gt;&gt;x; if(pos[x]){//栈中已出现x，将x提到栈顶，剩下的页面往下移 for(int i=pos[x];i&lt;cnt;++i)stk[i]=stk[i+1],pos[stk[i]]=i; //!!!这个代码不是特别对的地方就是这里，这里不能使用for循环，采用链表可以提升效率。 stk[cnt]=x,pos[x]=cnt; } else{//x未出现 if(cnt!=n)stk[++cnt]=x,pos[x]=cnt;//栈未满则直接添加 else{//栈满，移去最久未使用的页面，将x放栈顶 for(int i=1;i&lt;n;++i)stk[i]=stk[i+1],pos[stk[i]]=i; //！！！与上述同理。堆栈需要手动实现一个链表！！！！ stk[n]=x,pos[x]=n; } } } for(int i=1;i&lt;=cnt;++i)cout&lt;&lt;stk[i]&lt;&lt;(i==cnt?'\\n':' ');//输出当前栈中的页面号 } return 0;} &emsp;然后关于这次心态崩坏的头条三面就总结到这里了，希望能够尽快顺顺利利的获得一个保研offer或者薪水客观的校招offer。加油！！！！！！","link":"/2019/07/18/i-need-offer/"},{"title":"深入了解C++（3）——C++11特性小结","text":"&emsp;C++的第一版发布于98年，但是随着时代的变迁，一些更加现代化的思想也渐渐融入到C++的标准之中，特别显著的就是C++11的版本。今天就简要的介绍C++11的新特性。 一 nullptr&emsp;在C++11的新标准中，利用nullptr替换了NULL关键字。这个关键词的目的主要是解决0的二义性。我们可以从下面的示例代码简要了解C和C++中NULL通常的定义方式。 12345#ifdef __cplusplus ---简称：cpp c++ 文件#define NULL 0#else#define NULL ((void *)0)#endif &emsp;因为在C++中void*不能隐式的转换为其他类型的指针，然后为了为了解决空指针的问题所以特别引入0代表空指针的操作，但是这样的操作在下面的情况就会造成严重的二义性。 12void bar(sometype1 a, sometype2 *b);void bar(sometype1 a, int i); &emsp;为了解决二义性问题，有时候会采取这样的代码来避免二义性,即使用static_cast对0进行显式类型转换。 123bar(a, NULL)//×××bar(a, static_cast&lt;sometype2 *&gt;(0)); //√√√bar(a, static_cast&lt;sometype2 *&gt;(NULL)); //√√√ &emsp;上述的这种操作可以说是异常别扭的。在进行这样特殊的重载时，使用NULL必须使用手动转换，这可以说时让人十分头皮发麻的。所以这里引入nullptr极大程度的解决了这个问题。 1bar(a, nullptr)//√√√ C++11 &emsp;使用nullptr可以解决NULL的二义性问题，这可以说是一波让人心情舒畅的操作。 二 使用using代替typedef&emsp;使用using替代typedef的简要代码如下: 123456789typedef double db;//c98using db = double;//c++11using query_record = std::tuple&lt;time_t, std::string&gt;;//c++11template&lt;class T&gt; using twins = std::pair&lt;T, T&gt;；//更广泛的还可以用于模板 &emsp;就个人感觉而言，这种变化带来的最大优势如下： 123#define ll long longtypedef long long llusing ll = long long &emsp;使用typedef感觉会产生巨大的歧义，这句话的含义可以是ll=&gt;long long 但是其实某种意义上也能被理解为 long ll =&gt; long？？。不得不说这里利用using代替typedef让人无比的舒畅。 三 神器auto与基于范围的遍历&emsp;不得不说，在C++11中，对于程序员来说最让人欣喜的就是auto关键字。不管从哪方面来看，auto关键字都大大的减少了程序员敲键盘的频率（大雾）。有效的缓解了程序员的肌肉劳损。 &emsp;auto关键字的最大功能就是推测类型，然后我们还可以利用decltype获取变量的类型，简要的功能代码如下： 123456auto a = 1;auto task = std::function&lt;void ()&gt;([this, a] { ~~~~~});decltype(a) b = 2; &emsp;上述的代码可以说还是小case，auto关键词最大的优势可能在下面的新特性中： 12345678map&lt;int,int&gt;all;for(map&lt;int,int&gt;::iterator i(all.begin());i!=all.end();i++){ //~~~}for(auto &amp;i:all){ //~~~} &emsp;可以说简直让人爽到原地起飞，如果说map里面的类型名非常的长，这个时候利用auto就可以顺利的避开敲这么一长串。当然部分开发领域为了保证阅读时语义清晰，还是会采用上面的写法，but很显然下面的写法逐渐成了主流，毕竟python里面迭代一个容器只需要下面的代码： 123a = [1, 2, 3, 4, 5]for i in a: print(i) &emsp;虽然不知道这种迭代方式最初源自于哪个语言，但不得不说这是C++的一大进步。 四 右值引用&emsp;一般来说我们采用一个非常简单的方法来判断一个值是左值还是右值：看能不能对表达式取地址，如果能，则为左值，否则为右值。对于C++11来说右值引用主要是为了拯救函数的返回值。 &emsp;通常来说一个函数的返回值会销毁掉，比如下面的这个函数： 123456int add(int a,int b){ return a+b;}int main(){ int c = add(1, 2);} &emsp;这个函数返回的是一个临时变量，他在运算结束后就会被销毁。如同上面的变量C，它是利用add函数的返回的临时变量给自己赋值，然后临时变量在运行完该行代码后会被销毁。在C++11之前，为了减少这样的开销，通常人们会采用神奇的常用左值引用的办法。 123int main(){ const int &amp;c = add(1, 2);} &emsp;这样的操作虽然可以延长返回值的生命周期，但是缺点也是显而易见的，变量c的值可能被固定不能修改。 123int main(){ int &amp;&amp; c= add(1, 2);} &emsp;使用&amp;&amp;后可以使add的返回值重获新生。该返回值将会一直存活下去直到c变量消亡。 五 move&emsp;move其实是右值引用相关的内容，但是由于内容规划的问题不知道如何衔接了，所以特别开出另外一个板块。move的作用之一就是将一个左值转换成右值。主要用于下面的情况。 123456789101112131415161718192021222324 // 构造函数MyString(const char* cstr=0){ if (cstr) { m_data = new char[strlen(cstr)+1]; strcpy(m_data, cstr); } else { m_data = new char[1]; *m_data = '\\0'; }}// 拷贝构造函数MyString(const MyString&amp; str) { CCtor ++; m_data = new char[ strlen(str.m_data) + 1 ]; strcpy(m_data, str.m_data);} // 移动构造函数MyString(MyString&amp;&amp; str) noexcept :m_data(str.m_data) { MCtor ++; str.m_data = nullptr; //不再指向之前的资源了} &emsp;首简要贴出三种构造函数。 1234567891011vector&lt;Mystring&gt; vec_str;for(int i(0);i&lt;100;i++){ Mystring a = \"hello world\" vec_str.push_back(a);}vector&lt;Mystring&gt; vec_str;for(int i(0);i&lt;100;i++){ Mystring a = \"hello world\" vec_str.push_back(std::move(a));} &emsp;通过自定义的类我们可以发现，前一段代码调用了拷贝构造函数，而后一段代码调用了移动构造函数。 &emsp;最后作为总结贴出一个利用move的特性构造的swap。在类定义了移动拷贝函数时，这种方式将大大降低开销，在没有定义时它跟普通函数相似。 1234567template &lt;typename T&gt;void swap(T&amp; a, T&amp; b){ T tmp(std::move(a)); a = std::move(b); b = std::move(tmp);} 总结&emsp;这篇东西是在晚上睡不着觉但是又不想刷手机的时候查资料敲出来的，不知道有没有错，但是其实是知道关于右值引用的部分写的是有一定的欠缺的。倘若未来有幸使用C++11进行真正的工程时间，必将把该部分继续完善。頑張りましょう～","link":"/2019/07/21/cpp11-feature/"},{"title":"浅析ICMP协议","text":"&emsp;前一段时间碰到一个面试题，问题是ping命令使用的是什么协议，这个问题的答案就是今天的主角ICMP协议。但是那个时候只知其名不知其今天就查阅资料简要总结ICMP协议。 一 ICMP简介&emsp;ICMP协议是一个网络层协议。 一个新搭建好的网络，往往需要先进行一个简单的测试，来验证网络是否畅通；但是IP协议并不提供可靠传输。如果丢包了，IP协议并不能通知传输层是否丢包以及丢包的原因。所以我们就需要一种协议来完成这样的功能–ICMP协议。 &emsp;ICMP协议的功能主要有： 确认IP包是否成功到达目标地址 通知在发送过程中IP包被丢弃的原因 &emsp;需要注意的是ICMP是基于IP协议工作的，但是它并不是传输层的功能，因此仍然把它归结为网络层协议 。所以如果我们问ping的端口时什么的时候，我们应该回答的是ping命令基于ICMP是一个网络层的概念，而端口是传输层的概念，所以ICMP不需要关注端口号。 二 报文格式 &emsp;用来传送ICMP 报文的IP 数据包上实际上有不少字段。但是实际上与ICMP 协议相关的只有7 个子段。 1）协议；2）源IP 地址；3）目的IP 地址；4）生存时间；这四个包含在IP 首部的字段。5）类型；6）代码；7）选项数据；这三个包含在ICMP数据部分的字段。 &emsp;这里面，1)协议字段值是1。2)和3)是用来交流ICMP 报文的地址信息，没有特殊意义。对于理解ICMP 本身，重要的是5)，6)，7)三个字段。这里面的可以称为核心的重要字段是5)类型，6)代码这两个字段。所有ICMP 用来交流错误通知和信息询问的报文，都是由类型和代码的组合来表示的。RFC 定义了15种类型。“报文不可到达”这样的错误通知和“回送请求”这样的信息查询是由类型字段来区分的。ICMP报文由类型来表达它的大概意义，需要传递细小的信息时由代码来分类。进一步，需要向对方传送数据的时候，用7）选项数据字段来放置。引用自_毛台 三 常用的ICMP协议命令 ping（1）能验证网络的连通性 （2）会统计响应时间和TTL(IP包中的Time To Live，生存周期) tracert&emsp;打印出可执行程序主机，一直到目标主机之前经历多少路由器。 四 安全问题 引用自_毛台&emsp;作为恶意使用ICMP 的最有代表性的例子，也就是所谓的 “ping 洪水”的攻击。它利用ping 的原理，向目标服务器发送大量的ICMP 回送请求。这是黑客向特定的机器连续发送大量的ICMP 回送请求报文。目标机器回答到达的ICMP 回送请求已经用尽全力了，原来的通信处理就变得很不稳定了。进一步，目标机器连接的网络也可能由于大量的ICMP 数据包而陷入不可使用的状态。&emsp;与ping 洪水相似，以更加恶劣的使用方法而闻名的是称为“smurf”的攻击手法。smurf 同样，黑客恶意的使用ICMP 回送请求报文。这一点同ping 洪水是相同的。不过在smurf，对ICMP 回送请求实施了一些加工。源IP 地址被伪装成攻击对象服务器的地址，目标地址也不是攻击对象服务器的地址，而是成为中转台的网络的广播地址。","link":"/2019/07/22/icmp/"},{"title":"初窥http（3）——浅析http报文","text":"&emsp;今天一天给18级新生讲算法，但是呢日更还是得维持，所以就晚上更新一个简单一点的内容。今天的内容主要浅要分析http报文 一 请求报文和结构 &emsp;由上图可知，请求报文和响应报文的内容由下面的数据组成。 请求行&emsp;用于表示请求的方法，请求的URI和HTTP版本 状态行&emsp;包含表明响应结果的状态码，原因短语和 HTTP 版本。 首段字段&emsp;包含表示请求和响应的各种条件和属性的各类首部。&emsp;一般有4种首部，分别是：通用首部、请求首部、响应首部和实体 首部。 其他&emsp;可能包含 HTTP 的 RFC 里未定义的首部（Cookie 等） 二 HTTP传输与压缩&emsp;在http协议中有一种被称为内容编码的功能可以进行内容压缩。常用的内容编码如下: gzip（GNU●zip） compress（UNIX 系统的标准压缩） deflate（zlib） identity（不进行编码） 三 分割发送的分块编码 &emsp;分块传输编码会将实体主体分成多个部分（块）。每一块都会用十六进制来标记块的大小，而实体主体的最后一块会使用“0(CR+LF)” 来标记。 &emsp;使用分块传输编码的实体主体会由接收的客户端负责解码，恢复到编码前的实体主体。 &emsp;HTTP/1.1 中存在一种称为传输编码（Transfer Coding）的机制，它可以在通信时按某种编码方式传输，但只定义作用于分块传输编码中。 四 获取部分内容的范围请求&emsp;http协议中该部分的功能是为了在网速较慢的情况下，能够对大文件断点重传。通过在首部定义Range字段即可完成该功能。 12Range: bytes=5001-10000 单范围Range: bytes=-3000, 5000-7000 多范围","link":"/2019/07/23/http-head/"},{"title":"后端面试基础——进程与线程","text":"&emsp;刚刚经历了大学以来的第一次面试，不得不说头条作为宇宙厂面试有非常高的难度，平日进行的简单开发和底层的深入理解不可而与，为了更加透彻的理解进程与线程，这里特别对进程和线程相关的知识进行总结。并且利用准确的术语来表述进程和线程的特点以及关系。 一 进程的基本概念&emsp;进程是并发执行的程序在执行过程中分配和管理资源的基本单位，是一个动态概念，竞争计算机系统资源的基本单位。作为一个程序执行的一个实体，是系统分配资源的基本单位。 &emsp;进程通信主要有五种通信方式，分别是管道、命名管道、信号量、消息队列、共享内存。 二 线程的基本概念&emsp;线程是进程的一个执行单元，是进程的一个特定执行路径。当一个线程修改了进程的资源，同一个进程下的其他线程将会立即看到这种变化。 &emsp;相较于进程，由于线程共享进程中的全局变量，所以通常而言不需要特别的线程通信方式，在C/C++中我们常利用volatile关键词使编译器不对代码段进行优化，无需将该值放入寄存器中，使该值可以被外部改变。或者利用windows消息队列进行线程通信。此外还可以利用std中std::promise、std::packaged_task来进行线程通信。 三 进程和线程的主要区别及优势区别：1.代码段、内存:进程间相互独立，同一进程的各线程间共享。线程仅在同一个进程内可见。 2.通信：进程间通信IPC（管道、命名管道、信号量、共享内存、消息队列），线程间通信相对进程间通信更为简单，直接使用全局变量即可。但是使用时需要考虑锁机制和同步机制。 3.调度和切换：线程上下文切换比进程上下文切换快得多。 4.在多线程OS中，进程不是一个可执行的实体。 选择：1.需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程的代价是很大的。 2.线程的切换速度快，所以在需要大量计算，切换频繁时使用线程，还有耗时的操作时用使用线程可提高应用程序的响应。 3.因为对CPU系统的效率使用上线程更占优势，所以可能要发展到多机分布的用进程，多核分布用线程。 4.并行操作时用线程，如C/S架构的服务器端并发线程响应用户的请求。 5.需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。 资源引用：什么是进程？什么是线程？进程和线程之间的区别是什么？","link":"/2019/07/11/process-thread/"},{"title":"网络编程之python-socket编程","text":"&emsp;对于python的socket编程，在之前仅有非常基础的了解。通常来说我们会利用以下的代码完成我们的socket编程。 1234567while True: # 接受一个新连接: sock, addr = s.accept() # 阻塞 # 直接进行一些操作 # or 创建新线程来处理TCP连接: t = threading.Thread(target=tcplink, args=(sock, addr)) t.start() &emsp;直接进行一些操作将会造成非常严重的阻塞问题，直观的来看，似乎采用多线程/进程的方式可以解决这个问题，但是其实并不然如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。1 &emsp;很多人可能会采用线程池、进程池的方法减少创建和销毁进程线程的次数，降低系统因为销毁或者创建进程/线程消耗的系统资源。但是在大规模的系统中仍然可能会遇到瓶颈。所以这里我们会采用非阻塞式接口来解决这个问题。 一 非阻塞IO&emsp;在python-socket编程中，设置setblocking的值为False(默认为True)，那么现在accept()将不再阻塞。常规的非阻塞式IO的代码如下 2 1234567891011121314151617181920212223while True: try: conn, addr = sock.accept() # 被动接受TCP客户的连接，等待连接的到来，收不到时会报异常 print('connect by ', addr) conn_list.append(conn) conn.setblocking(False) # 设置非阻塞 except BlockingIOError as e: pass tmp_list = [conn for conn in conn_list] for conn in tmp_list: try: data = conn.recv(1024) # 接收数据1024字节 if data: print('收到的数据是{}'.format(data.decode())) conn.send(data) else: print('close conn',conn) conn.close() conn_list.remove(conn) print('还有客户端=&gt;',len(conn_list)) except IOError: pass &emsp;但是从上述的代码我们可以观察到，虽然非阻塞式IO解决了阻塞的问题，一个进程可以同时干其他的任务，但是非阻塞式IO是非常不被推荐的，由于不断地while(True)可能会导致CPU资源占满，无故消耗了许多不需要消耗的系统资源。 二 多路复用IOselect模型&emsp;把socket交给操作系统去监控，相当于找个代理人(select), 去收快递。快递到了,就通知用户，用户自己去取。&emsp;阻塞I/O只能阻塞一个I/O操作，而I/O复用模型能够阻塞多个I/O操作，所以才叫做多路复用 &emsp;使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求。用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在同一个线程内同时处理多个IO请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。 12345678910111213141516171819s_list = [s.fileno(),] #fileno()获取套接字的唯一描述符,每个套接字都是唯一不同的s_dict = {}while 1: list_readable,a,b = select(s_list,[],[]) #分别对应: 输入,输出,错误输出 for i in list_readable: if i == s.fileno(): conn,userinfo = s.accept() s_list.append(conn.fileno()) s_dict[conn.fileno()] = conn else: cs = s_dict[i] recv_data = cs.recv(1024) if len(recv_data) &lt;= 0: s_dict[i].close() s_dict.pop(i) s_list.remove(i) else: cs.send(recv_data) &emsp;但是select模型的复杂度较高，每次会不断的轮询所负责的所有socket描述符，当某个socket有数据到达了，就通知用户进程。所以select模型主要存在以下的问题 3 最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的，由 FD_SETSIZE 设置，默认值是 1024/2048 ，因此 Select 模型的最大并发数就被相应限制了。当然我们也可以采用修改FD_SETSIZE从而增加最大并发数。 效率问题， select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来，什么？都超时了。 内核 / 用户空间 内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法，在FD非常多的时候，非常的耗费时间。 &emsp;上述三点可以总结为：1.连接数受限 2.查找配对速度慢 3.数据由内核拷贝到用户态消耗时间 epoll模型&emsp;epoll模型是对select模型的改进，其效率非常高，但仅可用于Unix/Linux操作系统。由于其非常重要，这里完整摘取python源码。 4 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#创建socket对象serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)#设置IP地址复用serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)#ip地址和端口号server_address = (\"127.0.0.1\", 8888)#绑定IP地址serversocket.bind(server_address)#监听，并设置最大连接数serversocket.listen(10)print \"服务器启动成功，监听IP：\" , server_address#服务端设置非阻塞serversocket.setblocking(False) #超时时间timeout = 10#创建epoll事件对象，后续要监控的事件添加到其中epoll = select.epoll()#注册服务器监听fd到等待读事件集合epoll.register(serversocket.fileno(), select.EPOLLIN)#保存连接客户端消息的字典，格式为{}message_queues = {}#文件句柄到所对应对象的字典，格式为{句柄：对象}fd_to_socket = {serversocket.fileno():serversocket,}while True: print \"等待活动连接......\" #轮询注册的事件集合，返回值为[(文件句柄，对应的事件)，(...),....] events = epoll.poll(timeout) if not events: print \"epoll超时无活动连接，重新轮询......\" continue print \"有\" , len(events), \"个新事件，开始处理......\" for fd, event in events: socket = fd_to_socket[fd] #如果活动socket为当前服务器socket，表示有新连接 if socket == serversocket: connection, address = serversocket.accept() print \"新连接：\" , address #新连接socket设置为非阻塞 connection.setblocking(False) #注册新连接fd到待读事件集合 epoll.register(connection.fileno(), select.EPOLLIN) #把新连接的文件句柄以及对象保存到字典 fd_to_socket[connection.fileno()] = connection #以新连接的对象为键值，值存储在队列中，保存每个连接的信息 message_queues[connection] = Queue.Queue() #关闭事件 elif event &amp; select.EPOLLHUP: print 'client close' #在epoll中注销客户端的文件句柄 epoll.unregister(fd) #关闭客户端的文件句柄 fd_to_socket[fd].close() #在字典中删除与已关闭客户端相关的信息 del fd_to_socket[fd] #可读事件 elif event &amp; select.EPOLLIN: #接收数据 data = socket.recv(1024) if data: print \"收到数据：\" , data , \"客户端：\" , socket.getpeername() #将数据放入对应客户端的字典 message_queues[socket].put(data) #修改读取到消息的连接到等待写事件集合(即对应客户端收到消息后，再将其fd修改并加入写事件集合) epoll.modify(fd, select.EPOLLOUT) else: print 'closing', address, 'after reading no data' epoll.unregister(fd) connections[fd].close() del connections[fd] #可写事件 elif event &amp; select.EPOLLOUT: try: #从字典中获取对应客户端的信息 msg = message_queues[socket].get_nowait() except Queue.Empty: print socket.getpeername() , \" queue empty\" #修改文件句柄为读事件 epoll.modify(fd, select.EPOLLIN) else : print \"发送数据：\" , data , \"客户端：\" , socket.getpeername() #发送数据 socket.send(msg)#在epoll中注销服务端文件句柄epoll.unregister(serversocket.fileno())#关闭epollepoll.close()#关闭服务器socketserversocket.close() &emsp;但客户端的代码基本与其他模型无疑，这里对客户端代码做基本记录。 1234567891011121314151617#创建客户端socket对象clientsocket = socket.socket(socket.AF_INET,socket.SOCK_STREAM)#服务端IP地址和端口号元组server_address = ('127.0.0.1',8888)#客户端连接指定的IP地址和端口号clientsocket.connect(server_address)while True: #输入数据 data = raw_input('please input:') #客户端发送数据 clientsocket.sendall(data) #客户端接收数据 server_data = clientsocket.recv(1024) print '客户端收到的数据：'server_data #关闭客户端socket clientsocket.close() &emsp;通过上述的这些样例，大致了解了python如何利用内核模型进行编程，但是由于缺少编程经验，暂时尚未掌握这些操作在实习开发时如何运用。希望未来能对这个领域进行更深一步的理解，届时将再次更新总结对内核模型的理解。","link":"/2019/07/14/python-socket/"},{"title":"初窥http（3）——简要了解OSI七层模型&TCP/IP 四层模型","text":"一 OSI七层网络模型&emsp;OSI七层协议模型主要是：应用层（Application）、表示层（Presentation）、会话层（Session）、传输层（Transport）、网络层（Network）、数据链路层（Data Link）、物理层（Physical）。下面利用一张图片简要介绍各层的作用。 二 TCP/IP四层网络模型&emsp;TCP/IP模型主要讲OSI模型中部分概念合并，概念合并后如下表。 OSI七层网络 TCP/IP四层网络 对应网络协议 应用层（Application） 应用层 HTTP、TFTP, FTP, NFS, WAIS、SMTP 表示层（Presentation） Telnet, Rlogin, SNMP, Gopher 会话层（Session） SMTP, DNS 传输层（Transport） 传输层 TCP, UDP 网络层（Network） 网络层 IP, ICMP, ARP, RARP, AKP, UUCP 数据链路层（Data Link） 数据链路层 FDDI, Ethernet, Arpanet, PDN, SLIP, PPP 物理层（Physical） IEEE 802.1A, IEEE 802.2到IEEE 802.11 OSI引入了服务、接口、协议、分层的概念，TCP/IP借鉴了OSI的这些概念建立TCP/IP模型。 OSI先有模型，后有协议，先有标准，后进行实践；而TCP/IP则相反，先有协议和应用再提出了模型，且是参照的OSI模型。 OSI是一种理论下的模型，而TCP/IP已被广泛使用，成为网络互联事实上的标准。 三 常见协议的简单介绍 应用层 DHCP(动态主机分配协议) DNS (域名解析） FTP（File Transfer Protocol）文件传输协议 Gopher （英文原义：The Internet Gopher Protocol 中文释义：（RFC-1436）网际Gopher协议） HTTP （Hypertext Transfer Protocol）超文本传输协议 IMAP4 (Internet Message Access Protocol 4) 即 Internet信息访问协议的第4版本 IRC （Internet Relay Chat ）网络聊天协议 NNTP （Network News Transport Protocol）RFC-977）网络新闻传输协议 XMPP 可扩展消息处理现场协议 POP3 (Post Office Protocol 3)即邮局协议的第3个版本 SIP 信令控制协议 SMTP （Simple Mail Transfer Protocol）即简单邮件传输协议 SNMP (Simple Network Management Protocol,简单网络管理协议) SSH （Secure Shell）安全外壳协议 SSL: 安全套接字层协议； TELNET 远程登录协议 RPC （Remote Procedure Call Protocol）（RFC-1831）远程过程调用协议 RTCP （RTP Control Protocol）RTP 控制协议 RTSP （Real Time Streaming Protocol）实时流传输协议 TLS （Transport Layer Security Protocol）传输层安全协议 SDP( Session Description Protocol）会话描述协议 SOAP （Simple Object Access Protocol）简单对象访问协议 GTP 通用数据传输平台 STUN （Simple Traversal of UDP over NATs，NAT 的UDP简单穿越）是一种网络协议 NTP （Network Time Protocol）网络校时协议 传输层 TCP（Transmission Control Protocol）传输控制协议 UDP (User Datagram Protocol）用户数据报协议 DCCP （Datagram Congestion Control Protocol）数据报拥塞控制协议 SCTP（STREAM CONTROL TRANSMISSION PROTOCOL）流控制传输协议 RTP(Real-time Transport Protocol或简写RTP）实时传送协议 RSVP （Resource ReSer Vation Protocol）资源预留协议 PPTP ( Point to Point Tunneling Protocol）点对点隧道协议 网络层 IP(IPv4 · IPv6) Internet Protocol（网络之间互连的协议） ARP : Address Resolution Protocol即地址解析协议，实现通过IP地址得知其物理地址。 RARP :Reverse Address Resolution Protocol 反向地址转换协议允许局域网的物理机器从网关服务器的 ARP 表或者缓存上请求其 IP 地址。 ICMP :（Internet Control Message Protocol）Internet控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 IGMP :Internet 组管理协议（IGMP）是因特网协议家族中的一个组播协议，用于IP 主机向任一个直接相邻的路由器报告他们的组成员情况。 RIP : 路由信息协议（RIP）是一种在网关与主机之间交换路由选择信息的标准。 OSPF : (Open Shortest Path First开放式最短路径优先). BGP :（Border Gateway Protocol ）边界网关协议，用来连接Internet上独立系统的路由选择协议 IS-IS:（Intermediate System to Intermediate System Routing Protocol）中间系统到中间系统的路由选择协议. IPsec:“Internet 协议安全性”是一种开放标准的框架结构，通过使用加密的安全服务以确保在 Internet 协议 (IP) 网络上进行保密而安全的通讯。","link":"/2019/07/25/internet-OSI-TCP/"},{"title":"操作系统基础","text":"&emsp;本来以为自己的对于操作系统的基本理解应该是没有什么欠缺的，但是去搜刮了一波资料后发现自己好像啥都不会，本篇将主要总结：进程状态，CPU调度单位，中断实现机制，软硬中断的区别。 一 进程状态&emsp;通常而言，进程的状态分为两大类，一种是三模态，一种是五模态，它们的简介分别如下： 一个进程从创建而产生至撤销而消亡的整个生命期间，有时占有处理器执行，有时虽可运行但分不到处理器、有时虽有空闲处理器但因等待某个事件的发生而无法执行，这一切都说明进程和程序不相同，它是活动的且有状态变化的，这可以用一组状态加以刻画。为了便于管理进程，一般来说，按进程在执行过程中的不同情况至少要定义三种不同的进程状态： 运行(running)态：进程占有处理器正在运行。 就绪(ready)态：进程具备运行条件，等待系统分配处理器以便运行。 等待(wait)态：又称为阻塞(blocked)态或睡眠(sleep)态，指进程不具备运行条件，正在等待某个事件的完成。 通常，一个进程在创建后将处于就绪状态。每个进程在执行过程中，任意时刻当且仅当处于上述三种状态之一。同时，在一个进程执行过程中，它的状态将会发生改变。引起进程状态转换的具体原因如下： 运行态一一等待态：等待使用资源或某事件发生，如等待外设传输;等待人工干预。 等待态一一就绪态：资源得到满足或某事件己经发生，如外设传输结束；人工干预完成。 运行态一一就绪态：运行时间片到，或出现有更高优先权进程。 就绪态一一运行态：CPU空闲时被调度选中一个就绪进程执行。 &emsp;在实际的工作中，进程的状态转化通常比三模态更加复杂一些，所以这里就引入了一个五模态的概念。 在一个实际的系统里进程的状态及其转换比上节叙述的复杂一些，例如，引入专门的新建态(new)和终止态(exit )。引入新建态和终止态对于进程管理来说是非常有用的。新建态对应于进程刚刚被创建的状态，创建‘个进程要通过两个步骤，首先，是为一个新进程创建必要的管理信息；然后，让该进程进入就绪态。此时进程将处于新建态，它并没有被提交执行，而是在等待操作系统完成创建进程的必要操作。必须指出的是，操作系统有时将根据系统性能或主存容量的限制推迟新建态进程的提交。类似地，进程的终止也要通过两个步骤，首先，是等待操作系统进行善后；然后，退出主存。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止态。进入终止态的进程以后不再执行，但依然保留在操作系统中等待善后。一旦其他进程完成了对终止态进程的信息抽取之后，操作系统将删除该进程。引起进程状态转换的具体原因如下： NULL一一新建态:执行一个程序，创建一个子进程。 新建态一一就绪态:当操作系统完成了进程创建的必要操作，并且当前系统的性能和内存的容量均允许。 运行态一一终止态:当‘个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结。 终止态一一NULL:完成善后操作。 就绪态一一终止态:未在状态转换图中显示，但某些操作系统允许父进程终结子进程。 等待态一一终止态:未在状态转换图中显示，但某些操作系统允许父进程终结子进程。 &emsp;但是在linux系统中，进程的五种状态与上述的五模态还有一定的差别。linux系统中进程主要包含下面的五种状态： Linux进程状态：R (TASK_RUNNING)，可执行状态&amp;运行状态(在run_queue队列里的状态) Linux进程状态：S (TASK_INTERRUPTIBLE)，可中断的睡眠状态, 可处理signal Linux进程状态：D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态, 可处理signal,有延迟 Linux进程状态：T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态, 不可处理signal, 因为根本没有时间片运行代码 Linux进程状态：Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。不可被kill, 即不响应任务信号, 无法用SIGKILL杀死 &emsp;上述linux的五种状态在linux编程中有着非常重要的作用，这里很难三言两语将每个状态的作用详细介绍，日有有机会该部分将作为专题介绍。 二 CPU调度的最小单位&emsp;我们知道，在操作系统中，进程是操作系统分配的最小单位，对于cpu调度的最小单位不同地方有不同的答案。许多人认为线程是执行流的最小单位，但是对于cpu调度来说，每次执行并不一定完成一个线程的全部任务。我们可以发现所有的cpu调度算法都是为进程分配时间片，所以这里可以认为，时间片是cpu调度的基本单位。 三 软中断、硬中断&amp;&amp;实现机制&emsp;cpu和外部设备的速度总是不统一的，软件想要获取外部设备的状态主要有两种办法，一种是cpu不断地对所有的设备进行扫描，这样一旦设备发出信号，cpu就可以把时间告诉对应的应用程序。但是如果cpu同时连接了非常大量的外部设备，当一个设备发出信号时，cpu却在轮询其他设备，这中间的时间差会产生大量的延迟。而且cpu不断地访问空闲设备一定程序上也会浪费cpu的资源。 &emsp;所以在这里，操作系统会选择中断机制来解决这个问题。当没有中断产生的时候，cpu正常执行程序，当中断产生的时候，cpu会暂停当前进行的操作来处理中断，当中断处理完成后又将恢复执行正常程序。操作系统响应中断的基本流程如下。 产生中断——响应中断——关闭中断——保护中断——识别中断源——现场保护——中断服务——现场恢复。 &emsp;中断又常被分为软中断和硬中断对于他们的特点引用csdn博客内容： 硬中断： 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。 处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主CPU的支持下，可以同时处理多个中断。）。 硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。 对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。 软中断： 软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。 通常，软中断是一些对I/O的请求。这些请求会调用内核中可以调度I/O发生的程序。对于某些设备，I/O请求需要被立即处理，而磁盘I/O请求通常可以排队并且可以稍后处理。根据I/O模型的不同，进程或许会被挂起直到I/O完成，此时内核调度器就会选择另一个进程去运行。I/O可以在进程之间产生并且调度过程通常和磁盘I/O的方式是相同。 软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。 软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。 &emsp;这里引用百度百科介绍中断的概念。 虽然人们在谈到中断（Interrupt）时，总会拿轮询（Polling）来做“反面”例子，但中断和轮询并不是完全对立的两个概念，呃，它们是对立统一的。“CPU执行完每条指令时，都会去检查一个中断标志位”，这句话是所有关于中断长篇大论的开场白，但很容易被人忽略，其实，这就是中断的本质。举个例子，CPU老板是一家公司的光杆司令，所有的顾客都要他亲自跑去处理，还要跟有关部门打点关系，CPU觉得顾客和公关这两样事它一个人搞不来，这就是轮询；终于这家公司升级发展了，CPU老板请了一个秘书，所有的顾客都先由秘书经手，CPU心情好的时候就去看一下，大部分时间都忙着去公关了，这时它觉得轻松了很多，这就是中断了~~也就是说，中断和轮询是从CPU老板的角度来看的，不管怎样，事件都还是有人来时刻跟踪才能被捕获处理，不过是老板还是秘书的问题。所有的中断（或者异步，回调等）背后都有一个轮询（循环，listener）。","link":"/2019/07/15/system-base/"},{"title":"操作系统——io操作小结","text":"&emsp;这里主要有四个概念，分别是同步io、异步io、阻塞io、非阻塞io。本文主要参照tengteng_的博客，简单总结这四个基本概念的含义。 一 同步 &emsp;所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。&emsp;例如普通B/S模式（同步）：提交请求-&gt;等待服务器处理-&gt;处理完毕返回 这个期间客户端浏览器不能干任何事 二 异步 &emsp;异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。&emsp;例如 ajax请求（异步）: 请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 三 阻塞 &emsp;阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。&emsp;有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回,它还会抢占cpu去执行其他逻辑，也会主动检测io是否准备好。 四 非阻塞 &emsp;非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。再简单点理解就是： 同步，就是我调用一个功能，该功能没有结束前，我死等结果。 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知）。 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。 非阻塞，就是调用我（函数），我（函数）立即返回，通过select通知调用者 五 总结 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回 &emsp;综上所述对此进行一些总结，通过学习生活中的观察我们可以发现，在我们日常生活中写的程序大多数都是同步的，通常来说我们的程序都需要立即执行得到结果。但是我们可以利用多线程或者进程设计一个异步的程序，在程序运行到一定的时候通过创建进程、线程来处理耗时较长的程序。而后在需要运算结果的时候对运算状态进行查询，这样可以使一个进程同时处理多种不同的任务。 本文引用自https://blog.csdn.net/crazy_tengt/article/details/79225913","link":"/2019/07/17/system-io/"},{"title":"头条C++后端面经","text":"","link":"/2019/07/29/头条C-后端面经/"},{"title":"深入了解C++（1）——C++内存分配机制","text":"&emsp;常常被人问到，会不会写C++，曾经以为了解对面对象编程，了解qt等开源的库之后，就可以称之为会写C++了。但是深入了解之后就会发现，C++其实并不是这么简单。作为本专题的第一篇记录，将从内存分配机制开始深入的剖析C++。 一 C++ 内存分配方式&emsp;在C++中内存被分为五个区分别是：堆、栈、自由存储区、全局/静态存储区、常量存储区。 栈：是分配给函数局部变量的存储单元，函数结束后，该变量的存储单元自动释放，效率高，分配的空间有限。 堆：由new创建，由delete释放的动态内存单元。如果用户不释放该内存，程序结束时，系统会自动回收。 自由存储区：由malloc创建，由free释放的动态内存单元，与堆类似。 全局（静态）存储去：全局变量和静态变量占一块内存空间。 常量存储区：存储常量，内容不允许更改。引用自ladybai &emsp;一般而言对于程序员，我们只需要去关注堆和栈的概念。相比堆，栈大量减少了内存的碎片问题，并且计算机在系统底层提供专门的指令执行，而new的机制相比更为复杂所以分配效率相较于栈更慢。 二 内存分配失败&emsp;根据许多血一般的教训，下列的代码在动态分配内存的时候至关重要。 12345object* c = new object();//在较新的标准中，使用 new（nothrow） 才会出现分配失败时返回nullptr if(c==nullptr){ //错误处理机制} &emsp;但是其实在较新的C++标准中，出现内存分配失败时会抛出 1std::bad_alloc &emsp;但是针对这个我们主要需要意识到一个问题，内存的分配可能失败。 三 new/operator new/placement new&emsp;为了防止反复的释放内存，C++除了最基本的new操作之外还提供了placement new的操作。下面简单介绍这三种不同的new操作 运算符 new = 先调用函数 operator new 分配空间 + 然后调用构造函数。 对于operator new 函数内部，他是通过再调用malloc函数，进行空间分配的（当然也可以重写一个自己的空间分配器）。 placement new 指的是，不进行分配空间，而是在指定的空间上面进行调用构造函数。当然，在析构的时候，也只能显示的调用析构函数。（因为并不是真正的释放空间）引用自爱秋刀鱼的猫 &emsp;下面简单给出new的代码。 123object* a = new object(); char* chunk = new(nothrow) char[10];object* b = new (chunk) object(); &emsp;那么其实来说就是上面的两种new，然后operator new的含义应该是仅分配内存但是不初始化函数。 &emsp;针对大多数场景，我们使用普通的new可以完成绝大多数任务。但是极少数情况，我们可能需要反复利用一块极大的内存空间，此时利用placement new可以减少内存空间的申请释放所消耗的时间。 四 总结&emsp;本篇主要简要介绍了C++内存分配的机制，并且了解了针对大块内存反复申请释放采用placement new的操作。本模块将持续更新，介绍更多关于C++更为深入的内容。","link":"/2019/07/20/cpp-memory/"},{"title":"操作系统——调度算法小结","text":"&emsp;真的是太懵圈了，突然发现操作系统还有调度算法这么一说。虽说操作系统课程已经过去了一年多了但是这种基础知识着实不能忘。 一 先来先服务算法&emsp;先来先服务算法是操作系统调度算法中最简单的算法，该算法可以用于作业调度，同样也可以用于进程调度，调度的策略非常简单，就是先来先服务。 二 短作业优先算法&emsp;短作业有限算法，同样作为操作系统调度算法中非常简单的算法，调度策略是优先选取运行所需时间短的任务。 三 高权值优先算法&emsp;这里分为抢占式和非抢占式算法，抢占式算法在高权值的任务进入时直接挤掉当前运行的任务。非抢占式算法在任务执行结束后，选取权值最高的任务执行。 四 高响应比优先算法&emsp;由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先权又相当于响应比RP。作业优先级随等待时间增高而增高。随着等待时间增加，将会越来越快的被分配到cpu 五 时间片轮转算法&emsp;给队列中的每一个任务分配固定的时间片，然后每个任务执行完固定的时间片后将被轮出。但是这种算法如果时间片大小过大，则会造成cpu资源的浪费，如果时间片过小进程间不断切换也会浪费cpu资源。 六 多级反馈队列算法&emsp;与时间片轮转算法非常相似，但是与其不同的式，拥有多个队列，当任务在第一个队列分配的时间片中无法完成全部任务时，将会被置入第二个队列中，分配给其的时间片大小会越来越大。由于大多数任务我们没有办法知道确切的运行时间。所以这种调度算法是目前最被广泛使用的调度算法。","link":"/2019/07/16/system-scheduling-algorithm/"}],"tags":[{"name":"c++","slug":"c","link":"/tags/c/"},{"name":"lambda","slug":"lambda","link":"/tags/lambda/"},{"name":"多线程","slug":"多线程","link":"/tags/多线程/"},{"name":"cpp","slug":"cpp","link":"/tags/cpp/"},{"name":"stl","slug":"stl","link":"/tags/stl/"},{"name":"thread","slug":"thread","link":"/tags/thread/"},{"name":"单例模式","slug":"单例模式","link":"/tags/单例模式/"},{"name":"图论","slug":"图论","link":"/tags/图论/"},{"name":"dijkstra","slug":"dijkstra","link":"/tags/dijkstra/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"跳表","slug":"跳表","link":"/tags/跳表/"},{"name":"线段树","slug":"线段树","link":"/tags/线段树/"},{"name":"线段数组","slug":"线段数组","link":"/tags/线段数组/"},{"name":"红黑树","slug":"红黑树","link":"/tags/红黑树/"},{"name":"操作系统","slug":"操作系统","link":"/tags/操作系统/"},{"name":"数组映射","slug":"数组映射","link":"/tags/数组映射/"},{"name":"http","slug":"http","link":"/tags/http/"},{"name":"TCP/IP","slug":"TCP-IP","link":"/tags/TCP-IP/"},{"name":"图解http","slug":"图解http","link":"/tags/图解http/"},{"name":"C++","slug":"C","link":"/tags/C/"},{"name":"虚函数","slug":"虚函数","link":"/tags/虚函数/"},{"name":"继承","slug":"继承","link":"/tags/继承/"},{"name":"重载","slug":"重载","link":"/tags/重载/"},{"name":"抽象类","slug":"抽象类","link":"/tags/抽象类/"},{"name":"数据库","slug":"数据库","link":"/tags/数据库/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"索引","slug":"索引","link":"/tags/索引/"},{"name":"https","slug":"https","link":"/tags/https/"},{"name":"ssl","slug":"ssl","link":"/tags/ssl/"},{"name":"非对称加密","slug":"非对称加密","link":"/tags/非对称加密/"},{"name":"今日头条","slug":"今日头条","link":"/tags/今日头条/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/计算机网络/"},{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"思维题","slug":"思维题","link":"/tags/思维题/"},{"name":"LRU算法","slug":"LRU算法","link":"/tags/LRU算法/"},{"name":"右值引用","slug":"右值引用","link":"/tags/右值引用/"},{"name":"auto","slug":"auto","link":"/tags/auto/"},{"name":"nullptr","slug":"nullptr","link":"/tags/nullptr/"},{"name":"ping","slug":"ping","link":"/tags/ping/"},{"name":"ICMP","slug":"ICMP","link":"/tags/ICMP/"},{"name":"面试","slug":"面试","link":"/tags/面试/"},{"name":"进程","slug":"进程","link":"/tags/进程/"},{"name":"线程","slug":"线程","link":"/tags/线程/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"socket","slug":"socket","link":"/tags/socket/"},{"name":"I/O","slug":"I-O","link":"/tags/I-O/"},{"name":"epoll","slug":"epoll","link":"/tags/epoll/"},{"name":"select","slug":"select","link":"/tags/select/"},{"name":"OSI","slug":"OSI","link":"/tags/OSI/"},{"name":"ISO","slug":"ISO","link":"/tags/ISO/"},{"name":"io","slug":"io","link":"/tags/io/"},{"name":"内存分配","slug":"内存分配","link":"/tags/内存分配/"},{"name":"调度算法","slug":"调度算法","link":"/tags/调度算法/"}],"categories":[{"name":"深入了解C++","slug":"深入了解C","link":"/categories/深入了解C/"},{"name":"算法基础","slug":"算法基础","link":"/categories/算法基础/"},{"name":"面试基础","slug":"面试基础","link":"/categories/面试基础/"},{"name":"初窥http","slug":"初窥http","link":"/categories/初窥http/"}]}